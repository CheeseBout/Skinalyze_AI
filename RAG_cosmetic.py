"""
RAG Cosmetic Chatbot Core - Stateless for NestJS Backend Integration
Merged Features: 
- Stateless design (NestJS handles session/history)
- Advanced Skin Condition Detection
- Currency Conversion (USD -> VND)
- Smart Product Grouping & Filtering
- VLM Skin Analysis (Base64/Bytes support)
"""

import os
import re
from pathlib import Path
import torch
from PIL import Image
import google.generativeai as genai
import base64
import io
import time
from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# =============================================================================
# CONFIGURATION
# =============================================================================
# Sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch khi deploy cÃ¹ng NestJS
PATH = Path(__file__).parent.resolve()
CHUNKS_FILE = PATH / "data" / "product_chunks.txt"
PERSIST_DIRECTORY = PATH / "db_chroma"
MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"

# Tá»· giÃ¡ USD â†’ VND (cá»‘ Ä‘á»‹nh)
USD_TO_VND = 26349

# Global cache for embeddings
_CACHED_EMBEDDINGS = None

# =============================================================================
# DATA MAPPING (Tá»ª FILE Má»šI)
# =============================================================================
SKIN_CONDITION_TO_SKIN_TYPE = {
    "acne": ["Há»—n há»£p", "Dáº§u", "Nháº¡y cáº£m"],  # Má»¥n
    "má»¥n": ["Há»—n há»£p", "Dáº§u", "Nháº¡y cáº£m"],
    "má»¥n trá»©ng cÃ¡": ["Há»—n há»£p", "Dáº§u", "Nháº¡y cáº£m"],
    
    "actinic keratosis": ["KhÃ´", "ThÆ°á»ng"],  # DÃ y sá»«ng
    "dÃ y sá»«ng": ["KhÃ´", "ThÆ°á»ng"],
    "da dÃ y sá»«ng": ["KhÃ´", "ThÆ°á»ng"],
    
    "phÃ¡t ban thuá»‘c": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],
    "phÃ¡t ban do thuá»‘c": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],
    
    "eczema": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],  # ChÃ m
    "chÃ m": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],
    "viÃªm da": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],
    
    "psoriasis": ["KhÃ´"],  # Váº£y náº¿n
    "váº£y náº¿n": ["KhÃ´"],
    
    "rosacea": ["Há»—n há»£p", "Dáº§u", "Nháº¡y cáº£m"],  # Trá»©ng cÃ¡ Ä‘á»
    "trá»©ng cÃ¡ Ä‘á»": ["Há»—n há»£p", "Dáº§u", "Nháº¡y cáº£m"],
    "da Ä‘á»": ["Há»—n há»£p", "Dáº§u", "Nháº¡y cáº£m"],
    
    "seborrheic keratoses": ["ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],  # ViÃªm da tiáº¿t bÃ£
    "viÃªm da tiáº¿t bÃ£": ["ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],
    
    "sun damage": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Nháº¡y cáº£m"],  # Tá»•n thÆ°Æ¡ng náº¯ng
    "tá»•n thÆ°Æ¡ng náº¯ng": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Nháº¡y cáº£m"],
    "hÆ° tá»•n do náº¯ng": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Nháº¡y cáº£m"],
    
    "tinea": ["Há»—n há»£p", "Dáº§u"],  # Náº¥m da
    "náº¥m da": ["Há»—n há»£p", "Dáº§u"],
    "náº¥m": ["Há»—n há»£p", "Dáº§u"],
    
    "warts": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],  # Má»¥n cÃ³c
    "má»¥n cÃ³c": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],
    "cÃ³c": ["Há»—n há»£p", "KhÃ´", "ThÆ°á»ng", "Dáº§u", "Nháº¡y cáº£m"],
}

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================
def setup_api_key():
    """Setup Google API Key"""
    # Attempt to get the key from the environment
    api_key = os.getenv("GOOGLE_API_KEY")

    if not api_key:
        print("\nâŒ CRITICAL ERROR: GOOGLE_API_KEY not found in environment variables.")
        print("Please create a .env file and add GOOGLE_API_KEY=your_new_key")
        # DO NOT fallback to a hardcoded key. It is a security risk.
        raise ValueError("GOOGLE_API_KEY is missing.")
    
    # Configure Gemini
    genai.configure(api_key=api_key)
    print("âœ… API Key configured successfully from environment!\n")

def extract_product_name(chunk_text):
    """TrÃ­ch xuáº¥t tÃªn sáº£n pháº©m tá»« chunk text"""
    # TÃ¬m "Product Name: ..."
    match = re.search(r'Product Name:\s*(.+?)(?:\n|$)', chunk_text, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    
    # TÃ¬m "TÃªn sáº£n pháº©m: ..."
    match = re.search(r'TÃªn sáº£n pháº©m:\s*(.+?)(?:\n|$)', chunk_text, re.IGNORECASE)
    if match:
        return match.group(1).strip()
    
    # Fallback: láº¥y dÃ²ng Ä‘áº§u tiÃªn
    lines = chunk_text.split('\n')
    for line in lines:
        if ':' in line:
            potential_name = line.split(':', 1)[1].strip()
            if len(potential_name) > 5:
                return potential_name
    return "Unknown Product"

def convert_price_in_text(text):
    """TÃ¬m vÃ  chuyá»ƒn Ä‘á»•i giÃ¡ USD sang VND trong text"""
    def replace_price(match):
        price_str = match.group(1)
        try:
            price_usd = float(price_str)
            price_vnd = int(price_usd * USD_TO_VND)
            return f"${price_usd:.0f} (â‰ˆ {price_vnd:,} VND)".replace(',', '.')
        except:
            return match.group(0)
    
    result = re.sub(r'\$([0-9]+(?:\.[0-9]+)?)', replace_price, text)
    return result

def detect_skin_condition_and_types(query):
    """PhÃ¡t hiá»‡n bá»‡nh da trong cÃ¢u há»i vÃ  tráº£ vá» loáº¡i da phÃ¹ há»£p"""
    query_lower = query.lower()
    for condition, skin_types in SKIN_CONDITION_TO_SKIN_TYPE.items():
        if condition in query_lower:
            return condition, skin_types
    return None, None

# =============================================================================
# VECTOR STORE
# =============================================================================
def load_or_create_vectorstore():
    """Load or create vector store (Robust Version from New File)"""
    global _CACHED_EMBEDDINGS
    
    print("=" * 80)
    print("ðŸ“š KHá»žI Táº O VECTOR STORE")
    print("=" * 80)
    
    try:
        # Load embedding model
        if _CACHED_EMBEDDINGS is not None:
            print(f"\nâš¡ Sá»­ dá»¥ng cached embedding model")
            embeddings = _CACHED_EMBEDDINGS
        else:
            print(f"\nâ³ Äang táº£i embedding model: {MODEL_NAME}...")
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            print(f"   ðŸ–¥ï¸ Sá»­ dá»¥ng thiáº¿t bá»‹: {device}")
            
            embeddings = HuggingFaceEmbeddings(
                model_name=MODEL_NAME,
                model_kwargs={'device': device},
                encode_kwargs={'normalize_embeddings': True}
            )
            _CACHED_EMBEDDINGS = embeddings
            print("âœ… ÄÃ£ táº£i embedding model!\n")

        # Load or create database
        if os.path.exists(PERSIST_DIRECTORY):
            print(f"ðŸ“‚ Loading Vector Store from: {PERSIST_DIRECTORY}")
            db = Chroma(
                persist_directory=str(PERSIST_DIRECTORY),
                embedding_function=embeddings
            )
            count = db._collection.count() if db._collection else 0
            print(f"âœ… Loaded {count} documents\n")
        else:
            print(f"ðŸ†• Creating new Vector Store from {CHUNKS_FILE.name}...\n")
            
            if not CHUNKS_FILE.exists():
                raise FileNotFoundError(f"File khÃ´ng tá»“n táº¡i: {CHUNKS_FILE}")
            
            loader = TextLoader(str(CHUNKS_FILE), encoding='utf-8')
            documents = loader.load()
            
            text_splitter = RecursiveCharacterTextSplitter(
                separators=["---"],
                chunk_size=400,
                chunk_overlap=50,
                length_function=len
            )
            docs = text_splitter.split_documents(documents)
            
            # THÃŠM METADATA product_name cho má»—i chunk (Logic tá»« file má»›i)
            for doc in docs:
                product_name = extract_product_name(doc.page_content)
                doc.metadata['product_name'] = product_name

            print(f"   âœ“ Split into {len(docs)} chunks with metadata")
            print("ðŸ’¾ Creating embeddings and saving to database...")
            
            # Batch processing for stability
            batch_size = 50
            total_docs = len(docs)
            db = Chroma.from_documents(
                documents=docs[:batch_size],
                embedding=embeddings,
                persist_directory=str(PERSIST_DIRECTORY)
            )
            
            for i in range(batch_size, total_docs, batch_size):
                batch_end = min(i + batch_size, total_docs)
                db.add_documents(docs[i:batch_end])
            
            print(f"âœ… Created Vector Store with {len(docs)} vectors\n")

        return db, embeddings
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        return None, None

# =============================================================================
# RAG CHAIN SETUP (Integrated Logic)
# =============================================================================
def setup_rag_chain(db):
    """Setup RAG chain with Advanced Prompt and Grouping"""
    print("\n" + "=" * 80)
    print("â›“ï¸ KHá»žI Táº O RAG CHAIN")
    print("=" * 80)
    
    # LLM
    print("\nðŸ¤– [1/3] Connecting to Google Gemini...")
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.1,
        max_output_tokens=1200,
        convert_system_message_to_human=True,
        request_options={"timeout": 60},
        max_retries=2
    )
    print("   âœ“ Connected to Gemini 2.0 Flash")
    
    # Retriever
    print("ðŸ” [2/3] Creating Retriever...")
    retriever = db.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 8,           # Fetch 8 chunks
            "fetch_k": 16,
            "lambda_mult": 0.7
        }
    )
    print("   âœ“ Retriever ready (MMR, Smart Grouping)")
    
    # Prompt Template (Updated from New File)
    print("ðŸ“ [3/3] Creating Prompt Template...")
    template = """Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n má»¹ pháº©m chuyÃªn nghiá»‡p, thÃ¢n thiá»‡n vÃ  hiá»ƒu tÃ¢m lÃ½ khÃ¡ch hÃ ng.

PHÃ‚N LOáº I CÃ‚U Há»ŽI VÃ€ CÃCH TRáº¢ Lá»œI:

ðŸ”¹ **CHÃ€O Há»ŽI/GIAO TIáº¾P CÆ  Báº¢N**
CÃ¢u há»i: "xin chÃ o", "hi", "hello"
â†’ "ChÃ o báº¡n! ðŸ‘‹ MÃ¬nh lÃ  trá»£ lÃ½ tÆ° váº¥n má»¹ pháº©m. Báº¡n muá»‘n tÃ¬m sáº£n pháº©m gÃ¬ hÃ´m nay? ðŸ˜Š"

ðŸ”¹ **Há»ŽI Vá»€ Bá»†NH DA (Æ¯U TIÃŠN CAO)**
CÃ¢u há»i: "tÃ´i bá»‹ má»¥n", "chÃ m", "váº£y náº¿n", "náº¥m da"...
â†’ **BÆ¯á»šC 1:** XÃ¡c Ä‘á»‹nh Bá»†NH DA vÃ  LOáº I DA PHÃ™ Há»¢P (Ä‘Ã£ cÃ³ trong context).
â†’ **BÆ¯á»šC 2:** Gá»¢I Ã 2 Sáº¢N PHáº¨M phÃ¹ há»£p nháº¥t tá»« database.

ðŸ”¹ **Há»ŽI Vá»€ Váº¤N Äá»€ DA/LOáº I Sáº¢N PHáº¨M**
CÃ¢u há»i: "da khÃ´", "da dáº§u", "kem dÆ°á»¡ng", "serum"...
â†’ Gá»£i Ã½ 2 sáº£n pháº©m PHÃ™ Há»¢P tá»« database, nÃªu rÃµ CÃ”NG Dá»¤NG vÃ  LOáº I DA phÃ¹ há»£p.

ðŸ”¹ **Há»ŽI GIÃ/MUA á»ž ÄÃ‚U**
â†’ "Xin lá»—i, mÃ¬nh chá»‰ tÆ° váº¥n vá» sáº£n pháº©m. Báº¡n cÃ³ thá»ƒ mua táº¡i store chÃ­nh hÃ£ng. MÃ¬nh tÆ° váº¥n thÃªm sáº£n pháº©m khÃ¡c nhÃ©? ðŸ˜Š"

---

**CHÃš Ã KHI TRáº¢ Lá»œI:**
- LuÃ´n THÃ‚N THIá»†N, dÃ¹ng "mÃ¬nh/báº¡n".
- **GROUNDING:** CHá»ˆ Gá»¢I Ã sáº£n pháº©m CÃ“ TRONG DATABASE bÃªn dÆ°á»›i.
- **Sá» LÆ¯á»¢NG:** Máº·c Ä‘á»‹nh 2 sáº£n pháº©m (trá»« khi user há»i cá»¥ thá»ƒ sá»‘ lÆ°á»£ng).
- **FORMAT:**
  **Sá»‘. TÃªn sáº£n pháº©m** GiÃ¡: XXX.XXX VND | Loáº¡i da: [...]
  CÃ´ng dá»¥ng: [tÃ³m táº¯t ngáº¯n]
- **KHÃ”NG HIá»‚N THá»Š USD**, chá»‰ hiá»ƒn thá»‹ VND.
- DÃ¹ng emoji phÃ¹ há»£p: ðŸ˜ŠðŸ’„âœ¨ðŸ’•ðŸ’Š

THÃ”NG TIN Sáº¢N PHáº¨M Tá»ª DATABASE:
{context}

Lá»ŠCH Sá»¬/CONTEXT CÃ‚U Há»ŽI:
{question}

TRáº¢ Lá»œI:"""
    
    prompt = ChatPromptTemplate.from_template(template)
    
    # Advanced Formatting Function (from New File)
    def format_docs(docs):
        """Format documents: NHÃ“M chunks theo product_name, chá»‰ láº¥y 2 sáº£n pháº©m Ä‘áº§u tiÃªn"""
        if not docs or len(docs) == 0:
            return "KHÃ”NG TÃŒM THáº¤Y Sáº¢N PHáº¨M TRONG DATABASE"
        
        # NhÃ³m cÃ¡c chunks theo product_name
        product_groups = {}
        for doc in docs:
            product_name = doc.metadata.get('product_name', 'Unknown Product')
            if product_name not in product_groups:
                product_groups[product_name] = []
            product_groups[product_name].append(doc)
        
        if not product_groups:
            return "KHÃ”NG TÃŒM THáº¤Y Sáº¢N PHáº¨M TRONG DATABASE"
        
        # Chá»‰ láº¥y 2 sáº£n pháº©m Ä‘áº§u tiÃªn (hoáº·c nhiá»u hÆ¡n náº¿u cáº§n logic má»Ÿ rá»™ng sau nÃ y)
        selected_products = list(product_groups.keys())[:2]
        
        formatted = []
        for i, product_name in enumerate(selected_products, 1):
            chunks = product_groups[product_name]
            product_info = f"=== Sáº¢N PHáº¨M {i}: {product_name} ===\n"
            for chunk in chunks:
                content = chunk.page_content.strip()
                # Ãp dá»¥ng chuyá»ƒn Ä‘á»•i tiá»n tá»‡
                content = convert_price_in_text(content)
                product_info += content + "\n"
            formatted.append(product_info)
        
        return "\n\n".join(formatted)
    
    rag_chain = (
        {
            "context": retriever | format_docs,
            "question": RunnablePassthrough()
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    
    print("\nâœ… RAG Chain ready!\n")
    return rag_chain

# =============================================================================
# VISION ANALYSIS - STATELESS (Accepts PIL Image or base64)
# =============================================================================
def analyze_skin_image(image_input, note: str = None):
    """
    Analyze skin image - STATELESS version
    Args:
        image_input: PIL Image, base64 string, or file path
    Returns:
        str: Analysis result
    """
    try:
        print("\nðŸ“¸ Analyzing skin image...")
        
        # Handle input types
        img = None
        if isinstance(image_input, str):
            if image_input.startswith('data:image'):
                image_input = image_input.split(',')[1]
            try:
                # Try base64
                image_bytes = base64.b64decode(image_input)
                img = Image.open(io.BytesIO(image_bytes))
            except:
                # Try file path
                img = Image.open(image_input)
        elif isinstance(image_input, Image.Image):
            img = image_input
        elif isinstance(image_input, bytes):
            img = Image.open(io.BytesIO(image_input))
        
        if img is None:
            raise ValueError("Invalid image input")

        # Use updated model from New File logic (Gemini 2.5 Flash if available, else 2.0)
        # Using 2.0 Flash Exp/Stable as a safe bet from the provided code context
        vision_model = genai.GenerativeModel('gemini-2.0-flash') 
        
        # Updated Prompt from New File (Severity Focused)
        vision_prompt = """Báº¡n lÃ  chuyÃªn gia da liá»…u. PhÃ¢n tÃ­ch áº£nh da vÃ  TÃ“M Táº®T NGáº®N Gá»ŒN:

1. LOáº I DA: (khÃ´/dáº§u/há»—n há»£p/nháº¡y cáº£m/thÆ°á»ng)

2. Váº¤N Äá»€ CHÃNH & Má»¨C Äá»˜ NGHIÃŠM TRá»ŒNG:
- Náº¿u cÃ³ má»¥n: loáº¡i má»¥n, má»©c Ä‘á»™ (NHáº¸/TRUNG BÃŒNH/Náº¶NG/Ráº¤T Náº¶NG)
- Náº¿u cÃ³ thÃ¢m/sáº¹o: má»©c Ä‘á»™, mÃ u sáº¯c
- Náº¿u cÃ³ lÃ£o hÃ³a: má»©c Ä‘á»™

3. Má»¨C Äá»˜ CHUNG: Chá»n 1 trong 4 (QUAN TRá»ŒNG):
   - NHáº¸: Váº¥n Ä‘á» nhá», tá»± chÄƒm sÃ³c.
   - TRUNG BÃŒNH: Cáº§n sáº£n pháº©m chuyÃªn dá»¥ng.
   - Náº¶NG: ViÃªm nhiá»u, cáº§n Ä‘iá»u trá»‹ tÃ­ch cá»±c.
   - Ráº¤T Náº¶NG: ViÃªm tráº§m trá»ng, sáº¹o nhiá»u, Cáº¦N Gáº¶P BÃC SÄ¨.

4. Gá»¢I Ã: (1 cÃ¢u ngáº¯n)

Tráº£ lá»i NGáº®N Gá»ŒN, báº±ng tiáº¿ng Viá»‡t."""

        if note:
            vision_prompt += f"\n\n Ghi chÃº thÃªm tá»« ngÆ°á»i dÃ¹ng: {note}"
        
        response = vision_model.generate_content([vision_prompt, img])
        analysis = response.text
        print("âœ… Analysis complete!")
        return analysis
        
    except Exception as e:
        print(f"âŒ Error analyzing image: {str(e)}")
        return None

# =============================================================================
# HELPER FUNCTIONS FOR NESTJS INTEGRATION
# =============================================================================
def analyze_with_context(question: str, conversation_history: list = None) -> str:
    """
    Analyze question with conversation context + Skin Condition Logic
    Args:
        question: User's question
        conversation_history: List of (user_msg, bot_response) tuples
    Returns:
        str: Enhanced query string for the RAG chain
    """
    # 1. Logic phÃ¡t hiá»‡n bá»‡nh da (tá»« file má»›i)
    detected_condition, suitable_skin_types = detect_skin_condition_and_types(question)
    
    enhanced_part = ""
    if detected_condition:
        skin_types_str = ", ".join(suitable_skin_types)
        enhanced_part = f"""
THÃ”NG TIN Bá»” SUNG Tá»ª Há»† THá»NG:
- PhÃ¡t hiá»‡n bá»‡nh da: {detected_condition}
- Loáº¡i da phÃ¹ há»£p: {skin_types_str}
- Vui lÃ²ng tÃ¬m sáº£n pháº©m cho cÃ¡c loáº¡i da: {skin_types_str}"""

    # 2. Logic Context
    context_str = ""
    if conversation_history:
        recent_context = conversation_history[-3:]
        context_str = "Lá»ŠCH Sá»¬ Há»˜I THOáº I Gáº¦N ÄÃ‚Y:\n" + "\n".join([
            f"User: {ctx[0]}\nBot: {ctx[1][:200]}..." 
            for ctx in recent_context
        ])

    # 3. Combine
    final_query = f"""{context_str}

CÃ‚U Há»ŽI HIá»†N Táº I: {question}
{enhanced_part}

HÃ£y tráº£ lá»i dá»±a trÃªn Lá»ŠCH Sá»¬ vÃ  cÃ¢u há»i hiá»‡n táº¡i."""

    return final_query

def build_image_analysis_query(skin_analysis: str, additional_text: str = None) -> str:
    """
    Build RAG query based on Image Analysis Result
    """
    # Check severity (logic from New File)
    is_severe = any(keyword in skin_analysis.upper() for keyword in ['Ráº¤T Náº¶NG', 'Ráº¤T NGHIÃŠM TRá»ŒNG', 'Cáº¦N Gáº¶P BÃC SÄ¨'])
    
    warning = "(Ráº¤T NGHIÃŠM TRá»ŒNG - Cáº¦N Gáº¶P BÃC SÄ¨)" if is_severe else "(tá»« phÃ¢n tÃ­ch áº£nh)"
    advice_req = "Gá»£i Ã½ 1-2 sáº£n pháº©m Há»– TRá»¢ NHáº¸ NHÃ€NG. NHáº¤N Máº NH: Cáº§n gáº·p bÃ¡c sÄ©." if is_severe else "TÆ° váº¥n 2-3 sáº£n pháº©m Cá»¤ THá»‚ phÃ¹ há»£p vá»›i Má»¨C Äá»˜."
    
    user_req = f"\nYÃªu cáº§u thÃªm cá»§a user: {additional_text}" if additional_text else ""
    
    return f"""TÃ¬nh tráº¡ng da {warning}:
{skin_analysis}
{user_req}

{advice_req}"""

def check_severity(analysis: str) -> bool:
    """Check if skin condition is severe"""
    if not analysis: return False
    return any(keyword in analysis.upper() for keyword in ['Ráº¤T Náº¶NG', 'Ráº¤T NGHIÃŠM TRá»ŒNG'])