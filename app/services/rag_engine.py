import os
import re
import google.generativeai as genai
from langchain_community.document_loaders import TextLoader
from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import base64
import io
from PIL import Image
from app.core.config import settings

class RAGEngine:
    def __init__(self):
        self.db = None
        self.rag_chain = None
        self.embeddings = None
        self.skin_map = {
            "acne": ["H·ªón h·ª£p", "D·∫ßu", "Nh·∫°y c·∫£m"],
            "actinic_keratosis": ["Kh√¥", "Th∆∞·ªùng"],
            # "drug_eruption": ["H·ªón h·ª£p", "Kh√¥", "Th∆∞·ªùng", "D·∫ßu", "Nh·∫°y c·∫£m"],
            "eczema": ["H·ªón h·ª£p", "Kh√¥", "Th∆∞·ªùng", "D·∫ßu", "Nh·∫°y c·∫£m"],
            "psoriasis": ["Kh√¥"],
            "rosacea": ["H·ªón h·ª£p", "D·∫ßu", "Nh·∫°y c·∫£m"],
            "seborrheic_keratoses": ["Th∆∞·ªùng", "D·∫ßu", "Nh·∫°y c·∫£m"],
            "sun damage": ["H·ªón h·ª£p", "Kh√¥", "Th∆∞·ªùng", "Nh·∫°y c·∫£m"],
            "tinea": ["H·ªón h·ª£p", "D·∫ßu"],
            "warts": ["H·ªón h·ª£p", "Kh√¥", "Th∆∞·ªùng", "D·∫ßu", "Nh·∫°y c·∫£m"],
            "normal": ["Th∆∞·ªùng"]
        }

    def initialize(self):
        print("‚è≥ Initializing RAG Engine...")
        if not settings.GOOGLE_API_KEY:
            raise ValueError("GOOGLE_API_KEY missing in .env")
        genai.configure(api_key=settings.GOOGLE_API_KEY)
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=settings.EMBEDDING_MODEL,
            model_kwargs={'device': 'cuda' if os.environ.get('CUDA_VISIBLE_DEVICES') else 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        self._load_vector_store()
        if self.db:
            self._setup_chain()
        print("‚úÖ RAG Engine Ready.")

    def _load_vector_store(self):
        if settings.DB_DIR.exists():
            self.db = Chroma(persist_directory=str(settings.DB_DIR), embedding_function=self.embeddings)
        elif settings.CHUNKS_FILE.exists():
            print("üÜï Creating new Vector Store...")
            loader = TextLoader(str(settings.CHUNKS_FILE), encoding='utf-8')
            docs = RecursiveCharacterTextSplitter(separators=["---"], chunk_size=400, chunk_overlap=50).split_documents(loader.load())
            
            for doc in docs:
                doc.metadata['product_name'] = self._extract_product_name(doc.page_content)
                
            self.db = Chroma.from_documents(docs, self.embeddings, persist_directory=str(settings.DB_DIR))
        else:
            print("‚ö†Ô∏è No data found to initialize Vector Store.")

    def _setup_chain(self):
        llm = ChatGoogleGenerativeAI(
            model=settings.GEMINI_TEXT_MODEL,
            temperature=0.1,
            max_output_tokens=1200,
            convert_system_message_to_human=True,
            max_retries=2
        )
        
        retriever = self.db.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 8, "fetch_k": 16, "lambda_mult": 0.7}
        )

        template = """B·∫°n l√† chuy√™n gia t∆∞ v·∫•n m·ªπ ph·∫©m. 
        CONTEXT: {context}
        HISTORY: {question}
        
        NHI·ªÜM V·ª§:
        - N·∫øu h·ªèi b·ªánh da: X√°c ƒë·ªãnh b·ªánh -> G·ª£i √Ω 2 s·∫£n ph·∫©m.
        - N·∫øu h·ªèi lo·∫°i da: G·ª£i √Ω 2 s·∫£n ph·∫©m ph√π h·ª£p.
        - Hi·ªÉn th·ªã gi√° VND (kh√¥ng USD).
        """
        
        prompt = ChatPromptTemplate.from_template(template)
        
        self.rag_chain = (
            {"context": retriever | self._format_docs, "question": RunnablePassthrough()}
            | prompt | llm | StrOutputParser()
        )

    def analyze_image(self, image_data, note: str = None) -> str:
        try:
            img = None
            if isinstance(image_data, bytes):
                img = Image.open(io.BytesIO(image_data))
            elif isinstance(image_data, str): # base64
                if "base64," in image_data: image_data = image_data.split(",")[1]
                img = Image.open(io.BytesIO(base64.b64decode(image_data)))
            
            model = genai.GenerativeModel(settings.GEMINI_VISION_MODEL)
            prompt = "Ph√¢n t√≠ch da: 1. Lo·∫°i da 2. V·∫•n ƒë·ªÅ & M·ª©c ƒë·ªô (NH·∫∏/TRUNG B√åNH/N·∫∂NG/R·∫§T N·∫∂NG). 3. G·ª£i √Ω ng·∫Øn."
            if note: prompt += f" Note: {note}"
            
            response = model.generate_content([prompt, img])
            return response.text
        except Exception as e:
            return f"Error analyzing image: {str(e)}"

    def check_severity(self, text: str) -> bool:
        return any(k in text.upper() for k in ['R·∫§T N·∫∂NG', 'R·∫§T NGHI√äM TR·ªåNG', 'SEVERE'])

    def detect_condition(self, query: str):
        q = query.lower()
        for k, v in self.skin_map.items():
            if k in q: return k, v
        return None, None

    # --- Helpers ---
    def _extract_product_name(self, text):
        match = re.search(r'Product Name:\s*(.+?)(?:\n|$)', text, re.IGNORECASE)
        return match.group(1).strip() if match else "Unknown"

    def _format_docs(self, docs):
        if not docs: return "KH√îNG T√åM TH·∫§Y S·∫¢N PH·∫®M"
        grouped = {}
        for d in docs:
            name = d.metadata.get('product_name', 'Unknown')
            if name not in grouped: grouped[name] = []
            grouped[name].append(d.page_content)
        
        # Take top 2
        result = []
        for name in list(grouped.keys())[:2]:
            text = "\n".join(grouped[name])
            # Convert Price
            text = re.sub(r'\$([0-9]+(?:\.[0-9]+)?)', 
                          lambda m: f"{int(float(m.group(1)) * settings.USD_TO_VND):,} VND", text)
            result.append(f"=== {name} ===\n{text}")
        return "\n\n".join(result)

    def extract_product_names(self, rag_response: str) -> list:
        """
        Tr√≠ch xu·∫•t t√™n s·∫£n ph·∫©m t·ª´ RAG response
        Returns: List of product names only
        """
        import re
        product_names = []
        
        # Pattern 1: T√¨m c√°c d√≤ng c√≥ "=== Product Name ==="
        pattern1 = r'===\s*(.+?)\s*==='
        matches1 = re.findall(pattern1, rag_response)
        product_names.extend(matches1)
        
        # Pattern 2: T√¨m "Product Name: ..."
        pattern2 = r'Product Name:\s*(.+?)(?:\n|$)'
        matches2 = re.findall(pattern2, rag_response, re.IGNORECASE)
        product_names.extend(matches2)
        
        # Pattern 3: T√¨m c√°c d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng s·ªë (1. Product, 2. Product)
        pattern3 = r'\d+\.\s*([^\n]+?)(?:\s*-|\s*\(|$)'
        matches3 = re.findall(pattern3, rag_response)
        product_names.extend(matches3)
        
        # Lo·∫°i b·ªè tr√πng l·∫∑p v√† clean up
        seen = set()
        cleaned = []
        for name in product_names:
            name = name.strip()
            # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü cu·ªëi
            name = re.sub(r'[\:\-\(].*$', '', name).strip()
            if name and name not in seen and len(name) > 3:
                seen.add(name)
                cleaned.append(name)
        
        # Gi·ªõi h·∫°n t·ªëi ƒëa 5 s·∫£n ph·∫©m
        return cleaned[:5]

    def get_skin_types_from_disease(self, disease_class: str) -> list:
        """
        Suy ra lo·∫°i da t·ª´ b·ªánh da d·ª±a tr√™n skin_map
        Returns: List of skin types (e.g., ["H·ªón h·ª£p", "D·∫ßu"])
        """
        # Chu·∫©n h√≥a disease_class v·ªÅ lowercase v√† thay th·∫ø kho·∫£ng tr·∫Øng b·∫±ng underscore
        disease_normalized = disease_class.lower().replace(" ", "_")
        
        # T√¨m tr·ª±c ti·∫øp trong skin_map
        if disease_normalized in self.skin_map:
            return self.skin_map[disease_normalized]
        
        # Th·ª≠ t√¨m v·ªõi c√°c bi·∫øn th·ªÉ kh√°c
        # V√≠ d·ª•: "Sun_Sunlight_Damage" -> "sun damage"
        disease_variants = [
            disease_normalized.replace("_", " "),  # sun_sunlight_damage -> sun sunlight damage
            disease_normalized.split("_")[0],       # sun_sunlight_damage -> sun
        ]
        
        for variant in disease_variants:
            if variant in self.skin_map:
                return self.skin_map[variant]
        
        # Fallback: tr·∫£ v·ªÅ t·∫•t c·∫£ lo·∫°i da
        return ["H·ªón h·ª£p", "Kh√¥", "Th∆∞·ªùng", "D·∫ßu", "Nh·∫°y c·∫£m"]

rag_engine = RAGEngine()